{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "sents = fake.sentences(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407107353210449\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import grpc\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# def run(host, port, model, signature_name):\n",
    "\n",
    "host = 'localhost'\n",
    "model = 'use'\n",
    "signature_name = 'serve'\n",
    "port = 8500\n",
    "channel = grpc.insecure_channel('{host}:{port}'.format(host=host, port=port))\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "start = time.time()\n",
    "for x in range(50):\n",
    "\n",
    "    # Call classification model to make prediction\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = model\n",
    "    # request.model_spec.signature_name = signature_name\n",
    "    request.inputs['inputs'].CopyFrom(tf.make_tensor_proto(sents, dtype=tf.dtypes.string))\n",
    "    # request.inputs['sepal_width'].CopyFrom(make_tensor_proto(3.2, shape=[1, 1]))\n",
    "    # request.inputs['petal_length'].CopyFrom(make_tensor_proto(5.9, shape=[1, 1]))\n",
    "    # request.inputs['petal_width'].CopyFrom(make_tensor_proto(2.3, shape=[1, 1]))\n",
    "\n",
    "    result = stub.Predict(request,10.0)\n",
    "    \n",
    "\n",
    "\n",
    "    # Reference:\n",
    "    # How to access nested values\n",
    "    # https://stackoverflow.com/questions/44785847/how-to-retrieve-float-val-from-a-predictresponse-object\n",
    "    # result.outputs[0]\n",
    "\n",
    "    len(result.outputs['outputs'])\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.105710983276367\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "DOCKER_HOST = 'localhost'\n",
    "\n",
    "start = time.time()\n",
    "for x in range(50):\n",
    "    data = {\n",
    "    \"inputs\":  sents,\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    x = requests.post(f'http://{DOCKER_HOST}:8503/v1/models/use:predict', json=data).json()\n",
    "    len(x['outputs'])\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.041076887398958206,\n",
       " 0.0488143116235733,\n",
       " -0.053028929978609085,\n",
       " 0.02703404799103737,\n",
       " 0.047207556664943695,\n",
       " 0.07293877750635147,\n",
       " 0.020211076363921165,\n",
       " -0.05845915898680687,\n",
       " -0.061308715492486954,\n",
       " 0.0014748353278264403]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.outputs['outputs'].float_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}